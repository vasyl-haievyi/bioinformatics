{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(filename) -> list:\n",
    "    f = open(filename)\n",
    "\n",
    "    sequence = \"\"\n",
    "    sequences = []\n",
    "\n",
    "    for line in f:\n",
    "        if line.startswith(\">\"):\n",
    "            if len(sequence) != 0:\n",
    "                sequences.append(sequence)\n",
    "                sequence = \"\"\n",
    "        else:\n",
    "            sequence += line.strip()\n",
    "\n",
    "    if sequence:\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta(filename, sequences):\n",
    "    f = open(filename, 'w')\n",
    "    for sequence in sequences:\n",
    "        f.write('>\\n')\n",
    "\n",
    "        for idx in range(0, len(sequence), 70):\n",
    "            f.write(sequence[idx:idx+70])\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_reads(sequence_file):\n",
    "    genom = read_fasta(sequence_file)[0]\n",
    "\n",
    "    read_length = 200\n",
    "    coverage = 5\n",
    "    gen_len = len(genom)\n",
    "\n",
    "    all_reads = gen_len - 1 - read_length\n",
    "    one_read_prob = read_length / gen_len\n",
    "    reads_num = 1\n",
    "    while one_read_prob * reads_num < coverage:\n",
    "        reads_num += 1\n",
    "\n",
    "    reads = []\n",
    "    for _ in range(reads_num):\n",
    "        start = random.randint(0, gen_len - read_length)\n",
    "        reads.append(genom[start:start+read_length])\n",
    "\n",
    "    write_fasta('sequence_reads.fasta', reads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(first : str, second :str) -> str:\n",
    "    joined = None\n",
    "    for length in range(1, max(len(first), len(second))):\n",
    "        try:\n",
    "            if first.endswith(second[:length]):\n",
    "                joined = first + second[length:]\n",
    "            elif second.endswith(first[:length]):\n",
    "                joined = second + first[length:]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class Cache:\n",
    "    def __init__(self, strings):\n",
    "        self._cache = dict()\n",
    "\n",
    "        for first, second in itertools.product(strings, repeat=2):\n",
    "            if first == second:\n",
    "                continue\n",
    "        \n",
    "            joined = join(first, second)\n",
    "            \n",
    "            if len(frozenset([first, second])) == 1:\n",
    "                print(frozenset([first, second]))\n",
    "\n",
    "            if joined:\n",
    "                self._cache[frozenset([first, second])] = joined\n",
    "\n",
    "    def remove(self, string):\n",
    "        for key in list(self._cache):\n",
    "            if string in key:\n",
    "                del self._cache[key]\n",
    "\n",
    "    def add(self, string, strings):\n",
    "        for other in strings:\n",
    "            if string == other:\n",
    "                continue\n",
    "\n",
    "            joined = join(string, other)\n",
    "\n",
    "            if not joined:\n",
    "                continue\n",
    "            \n",
    "            if string == joined or other == joined:\n",
    "                continue\n",
    "            \n",
    "            self._cache[frozenset([string, other])] = joined\n",
    "\n",
    "    def get(self, first, second) -> str:\n",
    "        key = frozenset([first, second])\n",
    "\n",
    "        if key in self._cache:\n",
    "            return self._cache[key]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_max(self):\n",
    "        if self._cache:\n",
    "            return max(self._cache.keys(), key=lambda x: len(self._cache[x]))\n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contigs():\n",
    "    reads_set = set(read_fasta('sequence_reads.fasta'))\n",
    "    sequence_pairs = Cache(reads_set)\n",
    "\n",
    "    import itertools\n",
    "    from collections import namedtuple\n",
    "    Contig = namedtuple('Contig', ['first', 'second', 'contig'])\n",
    "\n",
    "    while len(reads_set) != 1:\n",
    "        if len(sequence_pairs) == 0: # there is no sequence fragmets to create new contigs\n",
    "            break\n",
    "\n",
    "        maxContig = None\n",
    "\n",
    "        key = list(sequence_pairs.get_max())\n",
    "        first, second = key[0], key[1]\n",
    "        joined = sequence_pairs.get(first, second)\n",
    "\n",
    "        if not joined:\n",
    "            continue\n",
    "\n",
    "        if not maxContig:\n",
    "            maxContig = Contig(first, second, joined)\n",
    "        elif joined != first and joined != second:\n",
    "            maxContig = max(maxContig, Contig(first, second, joined), key=lambda x: len(x.contig))\n",
    "\n",
    "        if maxContig:\n",
    "            reads_set.discard(maxContig.first)\n",
    "            reads_set.discard(maxContig.second)\n",
    "            reads_set.add(maxContig.contig)\n",
    "\n",
    "            sequence_pairs.remove(maxContig.first)\n",
    "            sequence_pairs.remove(maxContig.second)\n",
    "            sequence_pairs.add(maxContig.contig, reads_set)\n",
    "\n",
    "            print('sequence fragmets left', len(reads_set))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    write_fasta('sequence_contigs.fasta', reads_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence fragmets left 83\n",
      "sequence fragmets left 82\n",
      "sequence fragmets left 81\n",
      "sequence fragmets left 80\n",
      "sequence fragmets left 79\n",
      "sequence fragmets left 78\n",
      "sequence fragmets left 77\n",
      "sequence fragmets left 76\n",
      "sequence fragmets left 75\n",
      "sequence fragmets left 74\n",
      "sequence fragmets left 73\n",
      "sequence fragmets left 72\n",
      "sequence fragmets left 71\n",
      "sequence fragmets left 70\n",
      "sequence fragmets left 69\n",
      "sequence fragmets left 68\n",
      "sequence fragmets left 67\n",
      "sequence fragmets left 66\n",
      "sequence fragmets left 65\n",
      "sequence fragmets left 64\n",
      "sequence fragmets left 63\n",
      "sequence fragmets left 62\n",
      "sequence fragmets left 61\n",
      "sequence fragmets left 60\n",
      "sequence fragmets left 59\n",
      "sequence fragmets left 58\n",
      "sequence fragmets left 57\n",
      "sequence fragmets left 56\n",
      "sequence fragmets left 55\n",
      "sequence fragmets left 54\n",
      "sequence fragmets left 53\n",
      "sequence fragmets left 52\n",
      "sequence fragmets left 51\n",
      "sequence fragmets left 50\n",
      "sequence fragmets left 49\n",
      "sequence fragmets left 48\n",
      "sequence fragmets left 47\n",
      "sequence fragmets left 46\n",
      "sequence fragmets left 45\n",
      "sequence fragmets left 44\n",
      "sequence fragmets left 43\n",
      "sequence fragmets left 42\n",
      "sequence fragmets left 41\n",
      "sequence fragmets left 40\n",
      "sequence fragmets left 39\n",
      "sequence fragmets left 38\n",
      "sequence fragmets left 37\n",
      "sequence fragmets left 36\n",
      "sequence fragmets left 35\n",
      "sequence fragmets left 34\n",
      "sequence fragmets left 33\n",
      "sequence fragmets left 32\n",
      "sequence fragmets left 31\n",
      "sequence fragmets left 30\n",
      "sequence fragmets left 29\n",
      "sequence fragmets left 28\n",
      "sequence fragmets left 27\n",
      "sequence fragmets left 26\n",
      "sequence fragmets left 25\n",
      "sequence fragmets left 24\n",
      "sequence fragmets left 23\n",
      "sequence fragmets left 22\n",
      "sequence fragmets left 21\n",
      "sequence fragmets left 20\n",
      "sequence fragmets left 19\n",
      "sequence fragmets left 18\n",
      "sequence fragmets left 17\n",
      "sequence fragmets left 16\n",
      "sequence fragmets left 15\n",
      "sequence fragmets left 14\n",
      "sequence fragmets left 13\n",
      "sequence fragmets left 12\n",
      "sequence fragmets left 11\n",
      "sequence fragmets left 10\n",
      "sequence fragmets left 9\n",
      "sequence fragmets left 8\n",
      "sequence fragmets left 7\n",
      "sequence fragmets left 6\n",
      "sequence fragmets left 5\n",
      "sequence fragmets left 4\n"
     ]
    }
   ],
   "source": [
    "sequence_file = './human_genome_short_fragment.fasta'\n",
    "# sequence_file = './human_genome_long_fragment.fasta'\n",
    "\n",
    "generate_reads(sequence_file)\n",
    "build_contigs()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21011ec3f8359e725d0e30ec23938534a924568987a65f39ffe672e6d708092d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('mldd': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
